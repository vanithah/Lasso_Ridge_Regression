{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is linear regression?\n",
    "In simple terms, linear regression is a method of finding the best straight line fitting to the given data, \n",
    "i.e. finding the best linear relationship between the independent and dependent variables.\n",
    "In technical terms, linear regression is a machine learning algorithm that finds the best linear-fit \n",
    "relationship on any given data, between independent and dependent variables. It is mostly done by the \n",
    "Sum of Squared Residuals Method.\n",
    "\n",
    "In this technique, the dependent variable is continuous, independent variable(s) can be continuous or discrete, \n",
    "and nature of regression line is linear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston=load_boston()\n",
    "type(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df=pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df['price']=boston.target                    # to get dependent variable\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=boston_df.drop('price',axis=1)\n",
    "x.head(3)\n",
    "y=boston_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS   RAD    TAX  \\\n",
      "220   0.35809   0.0   6.20   1.0  0.507  6.951  88.5  2.8617   8.0  307.0   \n",
      "71    0.15876   0.0  10.81   0.0  0.413  5.961  17.5  5.2873   4.0  305.0   \n",
      "240   0.11329  30.0   4.93   0.0  0.428  6.897  54.3  6.3361   6.0  300.0   \n",
      "6     0.08829  12.5   7.87   0.0  0.524  6.012  66.6  5.5605   5.0  311.0   \n",
      "417  25.94060   0.0  18.10   0.0  0.679  5.304  89.1  1.6475  24.0  666.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  \n",
      "220     17.4  391.70   9.71  \n",
      "71      19.2  376.94   9.88  \n",
      "240     16.6  391.25  11.38  \n",
      "6       15.2  395.60  12.43  \n",
      "417     20.2  127.36  26.64  \n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "#80% training data , 20% test data\n",
    "\n",
    "print(x_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the regression model\n",
    "reg= LinearRegression()\n",
    "reg= reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1= [-1.19443447e-01  4.47799511e-02  5.48526168e-03  2.34080361e+00\n",
      " -1.61236043e+01  3.70870901e+00 -3.12108178e-03 -1.38639737e+00\n",
      "  2.44178327e-01 -1.09896366e-02 -1.04592119e+00  8.11010693e-03\n",
      " -4.92792725e-01]\n",
      "a0= 38.09169492630278\n"
     ]
    }
   ],
   "source": [
    "print(\"a1=\",reg.coef_)\n",
    "print(\"a0=\",reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329    22.6\n",
      "371    50.0\n",
      "219    23.0\n",
      "403     8.3\n",
      "78     21.2\n",
      "       ... \n",
      "56     24.7\n",
      "455    14.1\n",
      "60     18.7\n",
      "213    28.1\n",
      "108    19.8\n",
      "Name: price, Length: 102, dtype: float64\n",
      "[24.88963777 23.72141085 29.36499868 12.12238621 21.44382254 19.2834443\n",
      " 20.49647539 21.36099298 18.8967118  19.9280658   5.12703513 16.3867396\n",
      " 17.07776485  5.59375659 39.99636726 32.49654668 22.45798809 36.85192327\n",
      " 30.86401089 23.15140009 24.77495789 24.67187756 20.59543752 30.35369168\n",
      " 22.41940736 10.23266565 17.64816865 18.27419652 35.53362541 20.96084724\n",
      " 18.30413012 17.79262072 19.96561663 24.06127231 29.10204874 19.27774123\n",
      " 11.15536648 24.57560579 17.5862644  15.49454112 26.20577527 20.86304693\n",
      " 22.31460516 15.60710156 23.00363104 25.17247952 20.11459464 22.90256276\n",
      " 10.0380507  24.28515123 20.94127711 17.35258791 24.52235405 29.95143046\n",
      " 13.42695877 21.72673066 20.7897053  15.49668805 13.98982601 22.18377874\n",
      " 17.73047814 21.58869165 32.90522136 31.11235671 17.73252635 32.76358681\n",
      " 18.7124637  19.78693475 19.02958927 22.89825374 22.96041622 24.02555703\n",
      " 30.72859326 28.83142691 25.89957059  5.23251817 36.72183202 23.77267249\n",
      " 27.26856352 19.29492159 28.62304496 19.17978838 18.97185995 37.82397662\n",
      " 39.22012647 23.71261106 24.93076217 15.88545417 26.09845751 16.68819641\n",
      " 15.83515991 13.10775597 24.71583588 31.25165267 22.16640989 20.25087212\n",
      "  0.59025319 25.44217132 15.57178328 17.93719475 25.30588844 22.3732326 ]\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "y_pred=reg.predict(x_test)\n",
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ways of improving the accuracy of a linear regression model?\n",
    "There could be multiple ways of improving the accuracy of a linear regression, most commonly used ways are as follows:\n",
    "1.\tOutlier Treatment:\n",
    "-Regression is sensitive to outliers, hence it becomes very important to treat the outliers with appropriate values. \n",
    "Replacing the values with mean, median, mode or percentile depending on the distribution can prove to be useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE= 5.783509315085134\n"
     ]
    }
   ],
   "source": [
    "rmse= np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "print('RMSE=',rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression score= 0.589222384918251\n"
     ]
    }
   ],
   "source": [
    "r2= r2_score(y_test,y_pred)\n",
    "print('regression score=',r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting:\n",
    "reasons for overfitting:\n",
    "1. insufficient data in training the model:\n",
    "    to overcome this, we may need to use more data for training\n",
    "2. imprper set of attributes are used or more weightage is given to less important attributes: \n",
    "    to overcome this, we may need to do regularization\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "### How to avoid Overfitting:\n",
    "\n",
    "The commonly used methodologies are:\n",
    "\n",
    "•\tCross- Validation: A standard way to find out-of-sample prediction error is to use 5-fold cross validation.\n",
    "\n",
    "•\tEarly Stopping: Its rules provide us the guidance as to how many iterations can be run before learner begins to over-fit.\n",
    "\n",
    "•\tPruning: Pruning is extensively used while building related models. It simply removes the nodes which add little predictive power for the problem in hand.\n",
    "\n",
    "•\tRegularization: It introduces a cost term for bringing in more features with the objective function. Hence it tries to push the coefficients for many variables to zero and hence reduce cost term.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression score= 0.7730135569264234\n"
     ]
    }
   ],
   "source": [
    "y_pred_train=reg.predict(x_train)\n",
    "\n",
    "r2_train= r2_score(y_train,y_pred_train)\n",
    "print('regression score=',r2_train) #r2 for train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from above we can see, \n",
    "r2 for test data is = 0.5892\n",
    "r2 for train data is = 0.7730\n",
    "so, this is an example of overfitting\n",
    "\n",
    "increase the train data size to 85% then check the r2: for this, r2 value is degrading though increasing train data size. so 2nd reason for overfitting is the reason here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/01/ridge-lasso-regression-python-complete-tutorial/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the use of regularisation? Explain L1 and L2 regularisations.\n",
    "Regularisation is a technique that is used to tackle the problem of overfitting of the model. \n",
    "When a very complex model is implemented on the training data, it overfits. \n",
    "At times, the simple model might not be able to generalise the data and the complex model overfits. \n",
    "To address this problem, regularisation is used.\n",
    "Regularisation is nothing but adding the coefficient terms (betas) to the cost function so that the terms are \n",
    "penalised and are small in magnitude. This essentially helps in capturing the trends in the data and at the \n",
    "same time prevents overfitting by not letting the model become too complex.\n",
    "\n",
    "•\tL1 or LASSO regularisation: Here, the absolute values of the coefficients are added to the cost function. \n",
    "    This can be seen in the following equation; the highlighted part corresponds to the L1 or LASSO regularisation. \n",
    "    This regularisation technique gives sparse results, which lead to feature selection as well.\n",
    " \n",
    "•\tL2 or Ridge regularisation: Here, the squares of the coefficients are added to the cost function. \n",
    "    This can be seen in the following equation, where the highlighted part corresponds to the L2 or Ridge regularisation.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors= x_train.columns\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOX       -16.123604\n",
       "DIS        -1.386397\n",
       "PTRATIO    -1.045921\n",
       "LSTAT      -0.492793\n",
       "CRIM       -0.119443\n",
       "TAX        -0.010990\n",
       "AGE        -0.003121\n",
       "INDUS       0.005485\n",
       "B           0.008110\n",
       "ZN          0.044780\n",
       "RAD         0.244178\n",
       "CHAS        2.340804\n",
       "RM          3.708709\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.Series(reg.coef_, predictors).sort_values()\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21a96008188>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef.plot(kind = 'bar',title = 'Modal coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose the value of the regularisation parameter (λ)?\n",
    "Selecting the regularisation parameter is a tricky business. If the value of λ is too high, \n",
    "it will lead to extremely small values of the regression coefficient β, which will lead to the model \n",
    "underfitting (high bias – low variance). On the other hand, if the value of λ is 0 (very small), \n",
    "the model will tend to overfit the training data (low bias – high variance).\n",
    "\n",
    "There is no proper way to select the value of λ. What you can do is have a sub-sample of data and \n",
    "run the algorithm multiple times on different sets. Here, the person has to decide how much variance \n",
    "can be tolerated. Once the user is satisfied with the variance, that value of λ can be chosen for the full dataset.\n",
    "One thing to be noted is that the value of λ selected here was optimal for that subset, not for the entire training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression / L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "Ridge Regression is a technique used when the data suffers from multicollinearity \n",
    "(independent variables are highly correlated). In multicollinearity, even though the least squares estimates \n",
    "(OLS) are unbiased, their variances are large which deviates the observed value far from the true value. \n",
    "By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors.\n",
    "\n",
    "Above, we saw the equation for linear regression. Remember? It can be represented as:\n",
    "\n",
    "y=a+ b*x\n",
    "\n",
    "This equation also has an error term. The complete equation becomes:\n",
    "\n",
    "\n",
    "y=a+b*x+e (error term),  [error term is the value needed to correct for a prediction error between the \n",
    "                          observed and predicted value]\n",
    "                          \n",
    "=> y=a+y= a+ b1x1+ b2x2+....+e, for multiple independent variables.\n",
    "\n",
    "In a linear equation, prediction errors can be decomposed into two sub components. First is due to the biased \n",
    "and second is due to the variance. Prediction error can occur due to any one of these two or both components. \n",
    "Here, we’ll discuss about the error caused due to variance.\n",
    "\n",
    "Ridge regression solves the multicollinearity problem through shrinkage parameter λ (lambda). Look at the equation below.\n",
    "<img src ='Ridge2.webp'>\n",
    "\n",
    "ridge regression, l2 regularization\n",
    "\n",
    "In this equation, we have two components. First one is least square term and other one is lambda of the summation of \n",
    "β2 (beta- square) where β is the coefficient. This is added to least square term in order to shrink the parameter to \n",
    "have a very low variance.\n",
    "\n",
    "Important Points:\n",
    "The assumptions of this regression is same as least squared regression except normality is not to be assumed\n",
    "Ridge regression shrinks the value of coefficients but doesn’t reaches zero, which suggests no feature selection feature\n",
    "This is a regularization method and uses l2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha is hyperparameter of Ridge, which means that they are not automatically learned by the model instead they have to be set manually. \n",
    "and as alpha tends to zero, the model tends to become linear regressi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef of important variables are adjusted (increased) and for non important variables decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse= 5.786600507471575 r2= 0.5887831595590791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "#alpha range=[0.01, 0.05, 0.5]\n",
    "\n",
    "ridgereg = Ridge(alpha = 0.001, normalize = True)     # change alpha value \n",
    "ridgereg.fit(x_train, y_train)\n",
    "pred = ridgereg.predict(x_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,pred))\n",
    "r2= r2_score(y_test, pred)\n",
    "print('rmse=', rmse,'r2=',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear reg</th>\n",
       "      <th>Ridge reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.119443</td>\n",
       "      <td>-0.115518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.044780</td>\n",
       "      <td>0.042209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>-0.008247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.340804</td>\n",
       "      <td>2.400948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-16.123604</td>\n",
       "      <td>-14.968214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.708709</td>\n",
       "      <td>3.764608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.003121</td>\n",
       "      <td>-0.004116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-1.386397</td>\n",
       "      <td>-1.325265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.244178</td>\n",
       "      <td>0.212107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-0.010990</td>\n",
       "      <td>-0.009531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-1.045921</td>\n",
       "      <td>-1.029205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.008117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>-0.492793</td>\n",
       "      <td>-0.484041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Linear reg  Ridge reg\n",
       "0    -0.119443  -0.115518\n",
       "1     0.044780   0.042209\n",
       "2     0.005485  -0.008247\n",
       "3     2.340804   2.400948\n",
       "4   -16.123604 -14.968214\n",
       "5     3.708709   3.764608\n",
       "6    -0.003121  -0.004116\n",
       "7    -1.386397  -1.325265\n",
       "8     0.244178   0.212107\n",
       "9    -0.010990  -0.009531\n",
       "10   -1.045921  -1.029205\n",
       "11    0.008110   0.008117\n",
       "12   -0.492793  -0.484041"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Linear reg', 'Ridge reg'])\n",
    "\n",
    "for i in range(len(ridgereg.coef_)):\n",
    "    df= df.append({'Linear reg':reg.coef_[i], 'Ridge reg':ridgereg.coef_[i]}, ignore_index= True)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21a99c48808>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors= x_train.columns\n",
    "coef = pd.Series(ridgereg.coef_, predictors).sort_values()\n",
    "coef.plot(kind = 'bar',title = 'Modal coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this data, rodge reg is not giving good pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression / L1 regression\n",
    "\n",
    "<img src= 'Lasso.webp'>\n",
    "Similar to Ridge Regression, Lasso (Least Absolute Shrinkage and Selection Operator) also penalizes the absolute size of the regression coefficients. In addition, it is capable of reducing the variability and improving the accuracy of linear regression models.  Look at the equation below: Lasso regression differs from ridge regression in a way that it uses absolute values in the penalty function, instead of squares. This leads to penalizing (or equivalently constraining the sum of the absolute values of the estimates) values which causes some of the parameter estimates to turn out exactly zero. Larger the penalty applied, further the estimates get shrunk towards absolute zero. This results to variable selection out of given n variables.\n",
    "\n",
    "Important Points:\n",
    "The assumptions of lasso regression is same as least squared regression except normality is not to be assumed\n",
    "Lasso Regression shrinks coefficients to zero (exactly zero), which certainly helps in feature selection\n",
    "Lasso is a regularization method and uses l1 regularization\n",
    "If group of predictors are highly correlated, lasso picks only one of them and shrinks the others to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminates less important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse= 5.808077411724805 r2= 0.5857250414078969\n"
     ]
    }
   ],
   "source": [
    "#alpha range=[0.01, 0.05, 0.5]\n",
    "\n",
    "lassoreg = Lasso(alpha = 0.001, normalize = True)     # change alpha value \n",
    "lassoreg.fit(x_train, y_train)\n",
    "pred = lassoreg.predict(x_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,pred))\n",
    "r2= r2_score(y_test, pred)\n",
    "print('rmse=', rmse,'r2=',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear reg</th>\n",
       "      <th>Ridge reg</th>\n",
       "      <th>Lasso reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.119443</td>\n",
       "      <td>-0.119011</td>\n",
       "      <td>-0.111736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.044780</td>\n",
       "      <td>0.044497</td>\n",
       "      <td>0.041836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.340804</td>\n",
       "      <td>2.347657</td>\n",
       "      <td>2.336289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-16.123604</td>\n",
       "      <td>-15.999080</td>\n",
       "      <td>-15.299428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.708709</td>\n",
       "      <td>3.714983</td>\n",
       "      <td>3.747444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.003121</td>\n",
       "      <td>-0.003232</td>\n",
       "      <td>-0.001773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-1.386397</td>\n",
       "      <td>-1.379994</td>\n",
       "      <td>-1.311913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.244178</td>\n",
       "      <td>0.240552</td>\n",
       "      <td>0.209805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-0.010990</td>\n",
       "      <td>-0.010822</td>\n",
       "      <td>-0.009537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-1.045921</td>\n",
       "      <td>-1.044136</td>\n",
       "      <td>-1.034956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.007832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>-0.492793</td>\n",
       "      <td>-0.491878</td>\n",
       "      <td>-0.494384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Linear reg  Ridge reg  Lasso reg\n",
       "0    -0.119443  -0.119011  -0.111736\n",
       "1     0.044780   0.044497   0.041836\n",
       "2     0.005485   0.003907  -0.000000\n",
       "3     2.340804   2.347657   2.336289\n",
       "4   -16.123604 -15.999080 -15.299428\n",
       "5     3.708709   3.714983   3.747444\n",
       "6    -0.003121  -0.003232  -0.001773\n",
       "7    -1.386397  -1.379994  -1.311913\n",
       "8     0.244178   0.240552   0.209805\n",
       "9    -0.010990  -0.010822  -0.009537\n",
       "10   -1.045921  -1.044136  -1.034956\n",
       "11    0.008110   0.008111   0.007832\n",
       "12   -0.492793  -0.491878  -0.494384"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Linear reg', 'Ridge reg','Lasso reg'])\n",
    "\n",
    "for i in range(len(ridgereg.coef_)):\n",
    "    df= df.append({'Linear reg':reg.coef_[i], 'Ridge reg':ridgereg.coef_[i], 'Lasso reg':lassoreg.coef_[i]}, ignore_index= True)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21a9a58d808>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictors= x_train.columns\n",
    "coef = pd.Series(lassoreg.coef_, predictors).sort_values()\n",
    "coef.plot(kind = 'bar',title = 'Modal coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
